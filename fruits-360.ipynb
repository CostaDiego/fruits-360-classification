{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task intends to measure your deep learning basic skills. We will provide you a dataset containing 131 different fruits. Download it from this [link](https:///www.kaggle.com/moltean/fruits), download it and upload it to your copy of this file\n",
    "\n",
    "You have to implement a Convolutional Neural Network to classify the input fruit image. For this task, you must follow the following rules:\n",
    "\n",
    "- Use a ResNet50 as your CNN backbone.\n",
    "- The model output must be a probability score for all the classes.\n",
    "- You can implement the model in any Deep Learning framework that you are used to use.\n",
    "- Make sure you write your code following the best practices.\n",
    "- Make sure you document all the steps you took to solve the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "\n",
    "#Auxiliary libraries\n",
    "from os import listdir, path\n",
    "import os\n",
    "\n",
    "#Configure memory usage to the GPU device\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring and defining the constants\n",
    "\n",
    "###----- Here the constants related to datasets and dataframes are being defined ----###\n",
    "BASE_FOLDER = 'data'\n",
    "TRAIN_FOLDER = 'data/Training' \n",
    "TEST_FOLDER = 'data/Test'\n",
    "TRAIN_DF = 'train_df.csv'\n",
    "TEST_DF = 'test_df.csv'\n",
    "COLUMNS = {\n",
    "    'LABEL':'label',\n",
    "    'FILE':'file'\n",
    "}\n",
    "\n",
    "###----- Here we define the params and hyperparams to train the model -----###\n",
    "INPUT_SHAPE = (100,100,3)\n",
    "IMG_SIZE = (100,100)\n",
    "VAL_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "SEED = 42\n",
    "CHECKPOINT_PATH = 'model/epoch-{epoch}_valloss-{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(data_folder, columns = COLUMNS):\n",
    "    \"\"\"Generate a dataframe containing the file path and the respective label\n",
    "    \n",
    "    Params:\n",
    "        data_folder:str - folder to witch the dataframe will be created (train or test).\n",
    "        \n",
    "        columns:dict - A dictionay to name the columns\n",
    "        \n",
    "    Returns:\n",
    "        dataframe:pd.DataFrame - The dataframe containing the files and labels.\n",
    "    \"\"\"\n",
    "    labels = listdir(data_folder)\n",
    "    \n",
    "    dataframe = pd.DataFrame()\n",
    "    \n",
    "    for lbl in labels:\n",
    "        data = {\n",
    "            columns['FILE'] : [path.join(lbl,file) for file in listdir(path.join(data_folder,lbl))],\n",
    "            columns['LABEL']: lbl\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        dataframe = dataframe.append(df)\n",
    "    \n",
    "    return dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def load_dataframe(df_path):\n",
    "    \"\"\"Loads the dataframe from the specified path\n",
    "    \n",
    "    Params:\n",
    "        df_path:str - Path to the dataframe to be loaded.\n",
    "        \n",
    "    Returns:\n",
    "        dataframe:(pd.DataFrame|None) - If the file exists, returns the dataframe, otherwise returns None.\n",
    "    \"\"\"\n",
    "    if path.isfile(df_path):\n",
    "        return pd.read_csv(df_path)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataframe\n",
    "#Try to load the train dataframe\n",
    "train_df = load_dataframe(path.join(BASE_FOLDER, TRAIN_DF))\n",
    "\n",
    "#Check if loading was succeful, if not, generates and saves the dataframe.\n",
    "if train_df is None:\n",
    "    train_df = generate_dataframe(TRAIN_FOLDER)\n",
    "    train_df.to_csv(path.join(BASE_FOLDER, TRAIN_DF),index=False)\n",
    "    \n",
    "#Try to load the test dataframe\n",
    "test_df = load_dataframe(path.join(BASE_FOLDER, TEST_DF))\n",
    "\n",
    "#Check if loading was succeful, if not, generates and saves the dataframe.\n",
    "if test_df is None:\n",
    "    test_df = generate_dataframe(TEST_FOLDER)\n",
    "    test_df.to_csv(path.join(BASE_FOLDER, TEST_DF),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = pd.unique(train_df['label']) #generate a list of classes\n",
    "QTT_CLASSES = CLASSES.shape[0] #counts the numbers of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the image data generator using the ResNet50 preprocess and make the pixel values be between 0 and 1\n",
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    rescale = 1./255,\n",
    "    validation_split = VAL_SIZE)\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54154 validated image filenames belonging to 131 classes.\n",
      "Found 13538 validated image filenames belonging to 131 classes.\n",
      "Found 22688 validated image filenames belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "#To optimize the RAM usage, we use the flow method from generator continuously provide images\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    directory = TRAIN_FOLDER,\n",
    "    x_col = COLUMNS['FILE'],\n",
    "    y_col = COLUMNS['LABEL'],\n",
    "    target_size = IMG_SIZE,\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = SEED,\n",
    "    subset = 'training',\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    directory = TRAIN_FOLDER,\n",
    "    x_col = COLUMNS['FILE'],\n",
    "    y_col = COLUMNS['LABEL'],\n",
    "    target_size = IMG_SIZE,\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = SEED,\n",
    "    subset = 'validation',\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory = TEST_FOLDER,\n",
    "    x_col = COLUMNS['FILE'],\n",
    "    y_col = COLUMNS['LABEL'],\n",
    "    target_size = IMG_SIZE,\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Resnet 50 with its tops layers\n",
    "resnet50 = ResNet50(\n",
    "    input_shape = INPUT_SHAPE,\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    pooling = 'avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ResNet model it is without the top layers so we customize to fits our needs\n",
    "inputs = resnet50.input\n",
    "\n",
    "layer = Dense(128, activation='relu')(resnet50.output)\n",
    "layer = Dense(128, activation='relu')(layer)\n",
    "\n",
    "outputs = Dense(QTT_CLASSES, activation='softmax')(layer)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the callbacks to use during training\n",
    "\n",
    "#Reduces learning rate on plateou\n",
    "reduceLROnplateou = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.001)\n",
    "\n",
    "#stops training when the validation loss doesn't improve\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights = True)\n",
    "\n",
    "#Saves the model checkpoint each time the validation loss improves\n",
    "checkPoint = ModelCheckpoint(\n",
    "    filepath = CHECKPOINT_PATH,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [reduceLROnplateou, earlyStopping, checkPoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1693/1693 [==============================] - 369s 218ms/step - loss: 0.4102 - accuracy: 0.8918 - val_loss: 0.1499 - val_accuracy: 0.9535 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1693/1693 [==============================] - 326s 192ms/step - loss: 0.0686 - accuracy: 0.9811 - val_loss: 0.5323 - val_accuracy: 0.8490 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1693/1693 [==============================] - 325s 192ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 0.0330 - val_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1693/1693 [==============================] - 327s 193ms/step - loss: 0.0457 - accuracy: 0.9881 - val_loss: 0.0065 - val_accuracy: 0.9979 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1693/1693 [==============================] - 330s 195ms/step - loss: 0.0335 - accuracy: 0.9918 - val_loss: 0.0287 - val_accuracy: 0.9910 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1693/1693 [==============================] - 330s 195ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.0528 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1693/1693 [==============================] - 329s 194ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0015 - val_accuracy: 0.9996 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1693/1693 [==============================] - 352s 208ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.0129 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1693/1693 [==============================] - 354s 209ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0059 - val_accuracy: 0.9987 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1693/1693 [==============================] - 363s 214ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.2930 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1693/1693 [==============================] - 363s 215ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.1873 - val_accuracy: 0.9487 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1693/1693 [==============================] - 363s 214ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0834 - val_accuracy: 0.9757 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "1693/1693 [==============================] - 363s 214ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.0145 - val_accuracy: 0.9959 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1693/1693 [==============================] - 363s 215ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0895 - val_accuracy: 0.9741 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1693/1693 [==============================] - 363s 215ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.0054 - val_accuracy: 0.9986 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1693/1693 [==============================] - 364s 215ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0062 - val_accuracy: 0.9983 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "1693/1693 [==============================] - 362s 214ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0773 - val_accuracy: 0.9764 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#Trains the model and saves the training history\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data = val_images,\n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = len(train_images),\n",
    "    validation_steps = len(val_images),\n",
    "    callbacks = callbacks,\n",
    "    workers = 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
